{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GlobalAveragePooling2D,Dense, BatchNormalization, Dropout, Flatten, Conv2D, MaxPooling2D,Activation\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "seeds = 41\n",
    "im_shape = (250,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87 images belonging to 1 classes.\n",
      "Found 2 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "Classes: ['Batagor']\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "val_data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "test_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory('dataset/train', target_size=im_shape, shuffle=True, seed=seeds,\n",
    "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n",
    "validation_generator = val_data_generator.flow_from_directory('dataset/validation', target_size=im_shape, shuffle=False, seed=seeds,\n",
    "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n",
    "\n",
    "test_generator = test_generator.flow_from_directory('dataset/test', target_size=im_shape, shuffle=False, seed=seeds,\n",
    "                                                     class_mode='categorical', batch_size=BATCH_SIZE)\n",
    "\n",
    "nb_train_samples = train_generator.samples\n",
    "nb_validation_samples = validation_generator.samples\n",
    "nb_test_samples = test_generator.samples\n",
    "classes = list(train_generator.class_indices.keys())\n",
    "print('Classes: '+str(classes))\n",
    "num_classes  = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 248, 248, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 124, 124, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 122, 122, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 61, 61, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 61, 61, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 59, 59, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 29, 29, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 53824)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               5382500   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,406,185\n",
      "Trainable params: 5,406,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),activation='relu',input_shape=(im_shape[0],im_shape[1],3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "5/5 [==============================] - 4s 626ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/12\n",
      "5/5 [==============================] - 4s 692ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/12\n",
      "5/5 [==============================] - 3s 648ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/12\n",
      "5/5 [==============================] - 4s 697ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/12\n",
      "5/5 [==============================] - 5s 875ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/12\n",
      "5/5 [==============================] - 4s 642ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/12\n",
      "5/5 [==============================] - 3s 585ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/12\n",
      "5/5 [==============================] - 3s 507ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/12\n",
      "5/5 [==============================] - 3s 546ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/12\n",
      "5/5 [==============================] - 3s 601ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11/12\n",
      "5/5 [==============================] - 3s 675ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/12\n",
      "5/5 [==============================] - 3s 587ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // BATCH_SIZE,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1,\n",
    "    validation_steps=nb_validation_samples // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_13812\\3492151276.py:6: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  score = model.evaluate_generator(validation_generator)\n",
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_13812\\3492151276.py:8: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  score = model.evaluate_generator(test_generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.0\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Load the best saved model\n",
    "from keras.models import load_model\n",
    "\n",
    "#model = load_model('../input/classify-food-datas-models/model.h5')\n",
    "model = load_model('model.h5')\n",
    "score = model.evaluate_generator(validation_generator)\n",
    "\n",
    "score = model.evaluate_generator(test_generator)\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
